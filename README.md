LLM Applications are challenging to test for quality and safety because of their creativity. It's possible that with the same prompt a different response is received. But it can suffer from Hallucinations, Data Leakage, toxic responses too. There may be times where no answers or a refusal to respond is the correct response. Production monitoring may be advisable and wise whether in an active or passive mode. 